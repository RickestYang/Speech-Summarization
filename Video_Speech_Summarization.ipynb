{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Speech Summarization Web App with Hugging Face Transformers and Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ky5pi0q8_wDP",
    "outputId": "0e5add76-9c03-4a4b-d674-52ccf0a1da19"
   },
   "source": [
    "## 1. Define extract audio, speech recognize and summary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gHUh8UMdADy5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pafy\n",
    "import torch\n",
    "import librosa\n",
    "import transformers\n",
    "import gradio as gr\n",
    "import moviepy.editor as mp\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "from pathlib import Path\n",
    "from gradio.mix import Series\n",
    "from pydub import AudioSegment\n",
    "from transformers import Wav2Vec2ForMaskedLM, Wav2Vec2Tokenizer\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5sy6Cx8ICCWJ"
   },
   "outputs": [],
   "source": [
    "def audio_from_url(url, dst_dir='data', name=None, format='wav'):\n",
    "    \"\"\"\n",
    "    Download video from url and save the audio from video\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    url : str\n",
    "        The video url\n",
    "    dst_dir : str\n",
    "        Download video in this directory\n",
    "    name : str\n",
    "        Audiofile's name, if none, assign the name as the video's title\n",
    "    format :\n",
    "        Format type for audio file, such as 'wav', 'mp3'. WAV preferred.\n",
    "        \n",
    "    Return\n",
    "    -------\n",
    "    str\n",
    "        audiofile's file path, pathlib instance\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(dst_dir)\n",
    "    except(FileExistsError):\n",
    "        pass\n",
    "    os.chdir(dst_dir)\n",
    "    \n",
    "    # download youtube video\n",
    "    video = pafy.new(url)\n",
    "    video = video.getbest()\n",
    "    video.download()\n",
    "    \n",
    "    if not name:\n",
    "        name = video.title\n",
    "    f_name = fr'{name}.{format}'\n",
    "    \n",
    "    video = mp.VideoFileClip(fr'{video.filename}', verbose=False)\n",
    "    \n",
    "    # save audio file\n",
    "    video.audio.write_audiofile(f_name, verbose=False, logger=None)\n",
    "    video.close()\n",
    "    os.remove(video.filename)\n",
    "    os.chdir('..')\n",
    "    \n",
    "    return Path(f\"{dst_dir}/{f_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f7ViSR1gCRNl"
   },
   "outputs": [],
   "source": [
    "def split_audio_by_sec(src, start, end, dst_dir='audio_chunks', filename='test'):\n",
    "    \"\"\"\n",
    "    Split audio by seconds, from start point to end point.\n",
    "    Then save the audio clip in destination directory by assigned filename.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    src : str\n",
    "        audio file path\n",
    "    \n",
    "    start : int\n",
    "        The starting position of the clip.\n",
    "    \n",
    "    end : int\n",
    "        The ending position of the clip.\n",
    "    \n",
    "    dst_dir : string\n",
    "        Name for destination directory, save clip under this folder.\n",
    "    \n",
    "    filename : string\n",
    "        File name for the clip.\n",
    "    \"\"\"\n",
    "    \n",
    "    t1 = start * 1000\n",
    "    t2 = end * 1000\n",
    "    clip = src[t1:t2]\n",
    "    \n",
    "    dst_dir = Path(f\"{dst_dir}/{filename}\")\n",
    "    \n",
    "    clip.export(dst_dir, bitrate='192k', format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7bNL5Rf5C-o7"
   },
   "outputs": [],
   "source": [
    "def split_audio(src, sec_per_split=20, dst_dir='audio_chunks'):\n",
    "    \"\"\" Split audio into clips.\n",
    "    \"\"\"\n",
    "    \n",
    "    # make directory for audio clips\n",
    "    try:\n",
    "        os.mkdir(dst_dir)\n",
    "    except(FileExistsError):\n",
    "        pass\n",
    "    \n",
    "    # load in audio with 16k frame rate\n",
    "    audio = AudioSegment.from_file(src).set_frame_rate(16000)\n",
    "    \n",
    "    total_secs = int(audio.duration_seconds)\n",
    "    \n",
    "    # Spliting audio\n",
    "    for i in range(0, total_secs, sec_per_split):\n",
    "        idx = str(i//sec_per_split).zfill(3)\n",
    "        f_name = f\"chunk_{idx}.wav\"\n",
    "        split_audio_by_sec(audio, i, i+sec_per_split, dst_dir=dst_dir, filename=f_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load tokenizer and model, define recognition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70ooy65NEm_H",
    "outputId": "f0bf95cd-03cc-4132-c221-f0f31a692b80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "Some weights of Wav2Vec2ForMaskedLM were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "\n",
    "model = Wav2Vec2ForMaskedLM.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "34CQ3P9GFqCO"
   },
   "outputs": [],
   "source": [
    "def transcript_audio_clips(src='audio_chunks'):\n",
    "    \"\"\" Speech recognition on all the audio clips. \"\"\"\n",
    "    \n",
    "    result = ''\n",
    "            \n",
    "    for file in os.listdir(src):\n",
    "        # load audio data\n",
    "        file = Path(f\"{src}/{file}\")\n",
    "        audio, _ = librosa.load(file, sr=16000)\n",
    "        \n",
    "        # speech recognition with pretrained model\n",
    "        input_values = tokenizer(audio, return_tensors=\"pt\").input_values\n",
    "        logits = model(input_values).logits\n",
    "        prediction = torch.argmax(logits, dim=-1)\n",
    "        transcription = tokenizer.batch_decode(prediction)[0]\n",
    "        \n",
    "        # concatenate transcripts\n",
    "        result += transcription.lower() + ' '\n",
    "        os.remove(file)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1TYnxi4cGARW"
   },
   "outputs": [],
   "source": [
    "def transcript_audio(url):\n",
    "    \"\"\" Perform speech recognition on url linked video. \"\"\"\n",
    "    \n",
    "    audio = audio_from_url(url)\n",
    "    \n",
    "    # directory for audio chunks/clips\n",
    "    dst_dir = audio.with_suffix('')\n",
    "    \n",
    "    # split audio by certain duration(/sec)\n",
    "    # if encounter memory crash, adjust sec_per_split to smaller number\n",
    "    split_audio(src=audio, sec_per_split=10, dst_dir=dst_dir)\n",
    "    \n",
    "    # recognize speech through all the clips, obtain result for whole speech\n",
    "    transcript = transcript_audio_clips(src=dst_dir)\n",
    "    \n",
    "    os.remove(audio)\n",
    "    os.rmdir(dst_dir)\n",
    "    \n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Hnfa97GvIY1k"
   },
   "outputs": [],
   "source": [
    "speech_recognizer = gr.Interface(\n",
    "    transcript_audio,\n",
    "    inputs=gr.inputs.Textbox(),\n",
    "    outputs='text'\n",
    ")\n",
    "\n",
    "summarizer = gr.Interface.load(\"sshleifer/distilbart-cnn-12-6\", src='huggingface')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Launch gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "vjDGOT_AJxdu",
    "outputId": "a4d3a1e2-7084-4fb5-a7ba-f7c55ad303ea",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7860/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x25ddffd0dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series(\n",
    "    speech_recognizer, \n",
    "    summarizer,\n",
    "    title=\"Video Speech Summarization\",\n",
    "    description=\"Given a video url, generate a summary on the video\\'s speech.\",\n",
    "    inputs=gr.inputs.Textbox(lines=2, placeholder='Paste video url here...', label='URL'),\n",
    "    outputs=gr.outputs.Textbox(label=\"English Summary\")\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Video Speech Summarization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
